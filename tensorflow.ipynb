{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOpSU9+lEFEzMfDNlKX3fQG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vmunteanu/devcon/blob/main/tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and utility functions:"
      ],
      "metadata": {
        "id": "8bdjSnOol2vM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def dataframe_to_dataset(dataframe):\n",
        "    label = dataframe.pop(\"label\").to_numpy(dtype=\"int\")\n",
        "    val = dataframe.to_numpy(dtype=\"str\")\n",
        "    return tf.data.Dataset.from_tensor_slices((val, label))\n",
        "\n",
        "\n",
        "def dataframe_split(dataframe):\n",
        "\n",
        "    l = len(dataframe) // 10\n",
        "    test_df = dataframe.iloc[:l, ]\n",
        "    val_df = dataframe.iloc[l:l+l, ]\n",
        "    tr_df = dataframe.iloc[2 * l:, ]\n",
        "\n",
        "    return tr_df, val_df, test_df"
      ],
      "metadata": {
        "id": "iWzkYE9UkJ-p"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load learning data:"
      ],
      "metadata": {
        "id": "gxpJHZjgl98u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5PIp0V0juA6"
      },
      "outputs": [],
      "source": [
        "words = pd.read_csv(\"/content/sample_data/words.txt\", header=None, names=['val'])\n",
        "words['label'] = 1\n",
        "\n",
        "ids = pd.read_csv(\"/content/sample_data/not_words.txt\", header=None, names=['val'])\n",
        "ids['label'] = 0\n",
        "\n",
        "words_tr, words_val, words_test = dataframe_split(words)\n",
        "ids_tr, ids_val, ids_test = dataframe_split(ids)\n",
        "\n",
        "train = pd.concat([ids_tr, words_tr], axis=0)\n",
        "validate = pd.concat([ids_val, words_val], axis=0)\n",
        "test = pd.concat([ids_test, words_test], axis=0)\n",
        "\n",
        "train = train.sample(frac=1).reset_index(drop=True)\n",
        "validate = validate.sample(frac=1).reset_index(drop=True)\n",
        "test = test.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "print(train.head)\n",
        "\n",
        "train_ds = dataframe_to_dataset(train)\n",
        "validate_ds = dataframe_to_dataset(validate)\n",
        "\n",
        "train_ds = train_ds.batch(len(train))\n",
        "validate_ds = validate_ds.batch(len(validate))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the model:"
      ],
      "metadata": {
        "id": "05N2gNNZmr7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = \"-0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "tokens = list(tokens)\n",
        "max_len = 64\n",
        "\n",
        "vectorize_layer = tf.keras.layers.TextVectorization(\n",
        "    standardize=\"strip_punctuation\",\n",
        "    output_mode='int',\n",
        "    split=\"character\",\n",
        "    output_sequence_length=max_len,\n",
        "    vocabulary=tokens)\n",
        "\n",
        "inputs = tf.keras.Input(shape=(1,), dtype=tf.string)\n",
        "x = tf.keras.layers.Dropout(0.1)(inputs)\n",
        "x = vectorize_layer(inputs)\n",
        "x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
        "\n",
        "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, output)\n",
        "\n",
        "model.compile(\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "dr_bNKLzmDsL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learn:"
      ],
      "metadata": {
        "id": "dlN2rfNVmRkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_ds, epochs=100, validation_data=validate_ds)"
      ],
      "metadata": {
        "id": "N13ZYaGtm8iM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model:"
      ],
      "metadata": {
        "id": "zf3yyE7wnILZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = test.pop(\"label\").to_numpy(dtype=\"int\")\n",
        "x = test.to_numpy(dtype=\"str\")\n",
        "\n",
        "score = model.evaluate(x=x,\n",
        "                        y=y,\n",
        "                        return_dict=True, verbose=2, batch_size=32)\n",
        "\n",
        "print('Test: ', score)"
      ],
      "metadata": {
        "id": "tVNQJizemSLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export the model to be used in Tensorflow Serving:"
      ],
      "metadata": {
        "id": "0XektpSTncG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/saved_model/words')"
      ],
      "metadata": {
        "id": "rLcAt8ydnbV2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Play:"
      ],
      "metadata": {
        "id": "8syq4fBXkuFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values = np.array([\n",
        "    \"george\",\n",
        "    \"net-banking\",\n",
        "    \"kyc\",\n",
        "    \"unsecured-lending\",\n",
        "    \"conturi\",\n",
        "    \"14343123\",\n",
        "    \"lkdsj0q93ure\",\n",
        "    \"abd19198e731231dfdas2d\",\n",
        "    \"abd19198e7-d02e-4d13-8709-9a9f46\"])\n",
        "\n",
        "prediction = model.predict(values)\n",
        "\n",
        "it = np.nditer(values, flags=['f_index'])\n",
        "\n",
        "for word in it:\n",
        "    confidence = prediction[it.index][0]\n",
        "\n",
        "    pred = \"NOT\"\n",
        "\n",
        "    if confidence > 0.8:\n",
        "        pred = \"WORD\"\n",
        "\n",
        "    print(word, \"-\", pred, \"({:.2f})\".format(confidence), end='\\n')"
      ],
      "metadata": {
        "id": "Y1i7iWHtktnc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}